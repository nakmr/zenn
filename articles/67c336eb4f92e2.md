---
title: "関数型プログラミングをPythonで実践してみよう"
emoji: "😊"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: [Python, 関数型プログラミング, OpenAI]
published: false
publication_name: "acntechjp"
---

<!-- textlint-disable -->
:::details change log
<!-- textlint-enable -->
2024/09/17 投稿
<!-- textlint-disable -->
:::
<!-- textlint-enable -->

# はじめに

本記事では、関数型プログラミングの基本的な概念を整理して、Pythonを使って関数型プログラミングを実践します。

本記事の土台は、筆者が関数型プログラミングについて学習/整理した内容なので、高度に専門的ではないことや、実践の過程であることに留意ください。


## 誰に向けた記事か

本記事は、こんな人に向けて書かれています。

- 関数型プログラミングがどんなものか、触りでいいから知りたい人
- Pythonで関数型プログラミングを実践すると、どんな風になるのか知りたい人
- ここまで読んで、なんか気になってしまった人


## 誰に向けた記事ではないか

本記事は、こんな人が読むと「自分向けじゃなかった、、、」となります。

- 数学的に厳密な関数型プログラミングを書きたい人
- もうすでに関数型プログラミングを実践していて、さらにレベルアップしたいと考えている人

## 本記事の概要

本記事では、生成AIとチャットする機能を題材に、Pythonを使って関数型プログラミングを実践します。
まずオブジェクト指向な書き方で機能を実装し、関数型プログラミングの観点からはどういった点が問題になるのかを確認した後、同機能を関数型プログラミングで書き直します。

## 本記事を読んだ後にどうなるか

本記事を読み終わると、あなたはこのような状態になっています。

- 関数のシグネチャに、その関数に関すること全てが表れている「嘘をつかない関数」の重要さを説明できる
- 読む前よりも、関数型プログラミングへの興味が強くなっている
- 何なら、好きになっている

## 何を実装するのか

本記事ではOpenAI APIを利用したLLMとのチャット機能を実装します。チャット機能は下記の要件を満たすものとします。

- チャット機能のUIはコンソールとする
- チャットを開始するとユーザが終了を要求するまで、チャットが継続する
- 1回のチャット開始から終了までの会話履歴は、全てLLMに送信する
  - ただし、簡単のため、トークン数の調整は行わない


# オブジェクト指向な書き方

まずはオブジェクト指向な書き方で、チャット機能を実装します。

オブジェクト指向の基本的な考え方は、役割ごとにクラスを作成し、そのクラスが（役割を担うために）必要とする処理（メソッド）をクラス内に実装します。
本記事では`ChatBot`クラスを作成し、このクラス内にチャット機能を実装していきます。


```python:oop.py
import httpx
from typing import Dict, Any, Optional, List


class ChatBot:
    def __init__(self, api_key: str):
        """
        ChatBotクラスのコンストラクタ。APIキーを設定し、メッセージ履歴を初期化します。

        Args:
            api_key (str): OpenAI APIキー。
        """
        self.api_key = api_key
        self.messages = []  # メッセージ履歴を保持するリスト

    def _create_and_send_message(self, user_message: str) -> str:
        """
        ユーザーからのメッセージを基にOpenAIとやり取りし、アシスタントからのレスポンスを取得します。

        Args:
            user_message (str): ユーザーからのメッセージ。

        Returns:
            Optional[str]: アシスタントからのメッセージ。失敗した場合はNone。
        """
        # メッセージ履歴にユーザーのメッセージを追加
        self.messages.append({"role": "user", "content": user_message})

        # OpenAI APIに送信するペイロードを作成
        payload = {
            "model": "gpt-4o",
            "messages": self.messages,
            "temperature": 0.7,
        }

        # OpenAI APIへのリクエスト
        url = "https://api.openai.com/v1/chat/completions"
        headers = {"Authorization": f"Bearer {self.api_key}", "Content-Type": "application/json"}

        try:
            response = httpx.post(url=url, headers=headers, json=payload, timeout=None)
            data = response.raise_for_status().json()
        except httpx.HTTPStatusError as exc:
            print(
                f"エラーが発生しました。ステータスコード: {exc.response.status_code}, メッセージ: {exc.response.text}"
            )

        # アシスタントのレスポンスを取得してメッセージ履歴に追加
        assistant_message = data["choices"][0]["message"]["content"]
        self.messages.append({"role": "assistant", "content": assistant_message})

        return assistant_message

    def start_chat(self) -> None:
        """
        LLMとのチャットを開始します。
        """
        while True:
            user_message = input("メッセージを入力してください (`/end` で終了): ")
            if user_message == "/end":
                break

            assistant_message = self._create_and_send_message(user_message)
            if assistant_message:
                print(f"LLM: {assistant_message}")


if __name__ == "__main__":
    import os
    from dotenv import load_dotenv

    load_dotenv()
    chatbot = ChatBot(api_key=os.getenv("OPENAI_API_KEY"))
    chatbot.start_chat()
```

:::message
OpenAI APIの利用にはPython用クライアントモジュール`openai`を利用するのが常套手段ですが、本記事では、HTTP通信に関わる例外処理について言及するために、あえて利用しません。
<!-- textlint-disable -->
:::
<!-- textlint-enable -->

<!-- textlint-disable -->
:::details 実行結果の例
<!-- textlint-enable -->
```bash
メッセージを入力してください (`/end` で終了): 今東京にいるんだけど、めちゃ暑いっす
LLM: 東京の夏は確かに暑いですね！湿度も高いので、体感温度がさらに上がります。水分をこまめに摂ること、日陰や冷房の効いた場所で休むことが大切です。もし外出するなら、帽子や日傘を使って日差しを避けると少し楽になりますよ。また、冷たい飲み物やアイスクリームを楽しむのもいいですね。本当に暑い日は、無理せず涼しい場所で過ごすことをお勧めします。体調には気をつけてくださいね！
メッセージを入力してください (`/end` で終了): 今僕はどこにいるんだっけ？
LLM: あなたは「今東京にいる」とおっしゃっていましたね。東京のどのエリアにいるかまではわかりませんが、東京の暑さには気をつけて過ごしてください。もし具体的な場所やおすすめのスポットについて知りたいことがあれば、教えてください！
メッセージを入力してください (`/end` で終了): /end
```
<!-- textlint-disable -->
:::
<!-- textlint-enable -->


# 関数型プログラミングの観点でツッコミを入れてみよう

いったん、オブジェクト指向を念頭にチャット機能を実装したところ、Pythonコードに、関数型プログラミングの観点からツッコミを入れてみましょう。
ツッコミを入れるためには、本記事における「関数型プログラミングとはなんぞや」が必要になるので、ここで定義します。


## 本記事における関数型プログラミングとは？

本記事で関数型プログラミングを実践するにあたって、「[なっとく！関数型プログラミング](https://www.shoeisha.co.jp/book/detail/9784798179803)」から、下記の用語と定義を拝借します。

**関数型プログラミング**

> 関数型プログラミングとは イミュータブルな値を操作する純粋関数を利用するプログラミングである (P.70)

**純粋関数**

> - 戻り値は1つだけ
> - 引数のみに基づいて戻り値を計算する
> - 既存の値を変更しない
> 
> (P.46)

また同書では、純粋関数の定義「引数にのみ基づいて戻り値を計算する」から、「関数のシグネチャは嘘をついてはいけない」としています。
関数のシグネチャとは関数名、引数、戻り値を表す部分を指します。

```python
def add_two_numbers(num1: int, num2: int) -> int: # <- シグネチャ
    return num1 + num2 # <- 本体（関数の実体）
```

「関数のシグネチャは嘘をつく」とは、関数がシグネチャに書いてある引数以外を利用した計算を行っていたり、戻り値以外を返す（例えば、例外のスロー）ことを指しています。
言い換えると、その関数が何をするのかはシグネチャに全て書いてあるべきであり、シグネチャから読み取れない処理を関数は行ってはいけない、ということを意味しています。

例えば上記関数`add_two_numbers`のシグネチャからは、「引数にある2つの整数（`int`型）を足した結果（`int`型であり、1つ）を返す」ことが容易に読み取れます。したがって、この関数のシグネチャは嘘つきでないと言えます。

本記事で関数型プログラミングを実践するにあたって、この指摘も関数型プログラミングの観点に加えます。


## 関数型ツッコミ

`ChatBot`クラスの各メソッドに対して関数型プログラミングの観点からツッコミを入れていきましょう。

### `def __init__(self, api_key: str):`

<!-- textlint-disable -->
:::message
<!-- textlint-enable -->
これはクラスをインスタンス化する際に実行される特殊メソッドのため、関数型プログラミングの観点でツッコミを入れるべきなのか判断に迷いますが、やってみましょう。
<!-- textlint-disable -->
:::
<!-- textlint-enable -->

クラスのフィールドとして会話履歴を保持するリスト`self.messages = []`を宣言しています。これはミュータブルなリストのため、関数型プログラミングの定義「イミュータブルな値を操作する」に反します。
関数型プログラミングに書き直すにあたっては、会話履歴が増えるたびに1つのリストに会話履歴を追加していくのではなく、会話履歴が追加された、新しいリストを返すように書き直す必要があります。

### `def _create_and_send_message(self, user_message: str) -> str:`






### `def start_chat(self) -> None:`


# 関数型プログラミングな書き方



<!-- textlint-disable -->
:::details コードの全体
<!-- textlint-enable -->
```python:fp.py
import httpx
from typing import Callable, Dict, Any, Optional, List, Tuple


def create_openai_payload(messages: List[Dict[str, str]]) -> Dict[str, Any]:
    """
    OpenAI APIに送信するためのペイロードを作成します。

    Args:
        messages (List[Dict[str, str]]): 送信するメッセージのリスト。各メッセージは辞書形式で、'role'（ユーザーまたはアシスタント）と'content'（メッセージ内容）を含みます。

    Returns:
        Dict[str, Any]: OpenAI APIに送信するためのペイロードデータ。
    """
    return {"model": "gpt-4o", "messages": messages, "temperature": 0.7}


def send_openai_request(payload: Dict[str, Any], api_key: str) -> Tuple[Optional[Dict[str, Any]], Optional[str]]:
    """
    OpenAI APIにリクエストを送信し、レスポンスを返します。

    Args:
        payload (Dict[str, Any]): OpenAI APIに送信するペイロード。
        api_key (str): OpenAI APIキー。

    Returns:
        Tuple[Optional[Dict[str, Any]], Optional[str]]: 成功した場合はレスポンスのデータを含む辞書、エラーが発生した場合はエラーメッセージ。
    """
    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    try:
        return httpx.post(url=url, headers=headers, json=payload, timeout=None).raise_for_status().json(), None
    except httpx.HTTPStatusError as exc:
        return None, f"Error while requesting. Status code: {exc.response.status_code}, Message: {exc.response.text}"


def chat_with_openai(
    api_request_func: Callable[[Dict[str, Any], str], Tuple[Optional[Dict[str, Any]], Optional[str]]],
    create_payload_func: Callable[[List[Dict[str, str]]], Dict[str, Any]],
    messages: List[Dict[str, str]],
    api_key: str,
) -> Optional[Dict[str, Any]]:
    """
    OpenAIとチャットを行い、レスポンスを取得します。

    Args:
        api_request_func (Callable): APIリクエストを送信する関数。
        create_payload_func (Callable): ペイロードを作成する関数。
        messages (List[Dict[str, str]]): 送信するメッセージのリスト。
        api_key (str): OpenAI APIキー。

    Returns:
        Optional[Dict[str, Any]]: 成功した場合はレスポンスのデータ、失敗した場合はNone。
    """
    payload = create_payload_func(messages)
    response, error_message = api_request_func(payload, api_key)

    if error_message:
        display_error_message(error_message)
        return None

    return response


def receive_user_message() -> str:
    """
    ユーザーからの入力メッセージを取得します。

    Returns:
        str: ユーザーが入力したメッセージ。
    """
    return input("メッセージを入力してください (`/end` で終了): ")


def display_message(message: str) -> None:
    """
    アシスタントからのメッセージを表示します。

    Args:
        message (str): アシスタントからのメッセージ。
    """
    print(f"LLM: {message}")


def display_error_message(error_message: str) -> None:
    """
    エラーメッセージを表示します。

    Args:
        error_message (str): 表示するエラーメッセージ。
    """
    print(error_message)


def init_message() -> List[str]:
    """
    メッセージの履歴を初期化します。

    Returns:
        List[str]: 空のメッセージ履歴リスト。
    """
    return []


def update_message_history(messages: List[Dict[str, str]], new_message: Dict[str, str]) -> List[Dict[str, str]]:
    """
    メッセージ履歴に新しいメッセージを追加します。

    Args:
        messages (List[Dict[str, str]]): 現在のメッセージ履歴。
        new_message (Dict[str, str]): 追加する新しいメッセージ。

    Returns:
        List[Dict[str, str]]: 更新されたメッセージ履歴。
    """
    return messages + [new_message]


def interact_with_llm_in_chat(api_key: str) -> None:
    """
    チャット形式でLLMと対話を行います。

    Args:
        api_key (str): OpenAI APIキー。
    """
    messages = init_message()

    while True:
        user_message = receive_user_message()
        if user_message == "/end":
            break

        messages = update_message_history(messages=messages, new_message={"role": "user", "content": user_message})
        response = chat_with_openai(
            api_request_func=send_openai_request,
            create_payload_func=create_openai_payload,
            messages=messages,
            api_key=api_key,
        )

        if response is None:
            break

        if response:
            llm_message = response["choices"][0]["message"]["content"]
            messages = update_message_history(
                messages=messages, new_message={"role": "assistant", "content": llm_message}
            )

            display_message(llm_message)


if __name__ == "__main__":
    import os
    from dotenv import load_dotenv

    load_dotenv()
    interact_with_llm_in_chat(api_key=os.getenv("OPENAI_API_KEY"))
```
:::


# 次のステップ

関数型プログラミングに限らず、関数のシグネチャに「その関数はどんな型（ドメイン）を引数として受け取るのか？」「どんな型を返すのか？」が示されていることが重要です。
これまで実装では、Pythonの組み込み型と標準ライブラリ `typing` を使ってきましたが、ユーザ定義型を使うことで、関数シグネチャが示す情報を充実させることが必要です。
そのため、次のステップとしては、Pythonの型システムを活用することで、関数のシグネチャを充実させることを目指します。


